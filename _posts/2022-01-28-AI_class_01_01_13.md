---
layout: single
title:  "AI Class 01 01 13 행렬"
categories: python
tag: python
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
---

![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://{{ site.url | remove_first: 'https://' | remove_first: 'http://' }}{{ page.url }}&count_bg=%23FFCF00&title_bg=%230045FF&icon=macys.svg&icon_color=%23FAFF00&title=hits&edge_flat=false)

## 행렬  
- 행렬(matrix) : 벡터를 원소로 가지는 2차원 배열  
- 행렬은 행(row)와 열(column)이라는 인덱스(index)를 가짐  
- 행렬의 특정 행(열)을 고정하면 행(열)벡터라고 부름  
- 행렬끼리 같은 모양을 가지면 덧셈, 뺄셈을 계산할 수 있다  
- 성분곱은 벡터와 똑같다  
- 스칼라곱도 백터와 차이가 없다  

![AI_class_01_01_13_01](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_01.png){: width="20%" height="20%"}{: .center}  

```python
X = np.array([[1,-2,3],
              [7,5,0],
              [-2,-1,2]])
```  

![AI_class_01_01_13_02](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_02.png){: width="50%" height="50%"}{: .center}  

### 전치행렬(transpose matrix)  
- 행과 열의 인덱스가 바뀐 행렬  

![AI_class_01_01_13_03](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_03.png){: width="70%" height="70%"}{: .center}  

### 행렬을 이해하기 1  
- 백터는 공간에서 한 점을 의미하고, **행렬은 여러 점들을 나타낸다**  
- 행렬의 행벡터 ![AI_class_01_01_13_04](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_04.png){: .center}는 i번째 데이터를 의미한다  
- 행렬의 ![AI_class_01_01_13_06](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_06.png){: .center}는 i번째 데이터의 j번째 변수의 값  

![AI_class_01_01_13_05](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_05.png){: width="70%" height="70%"}{: .center}  

### 행렬 곱셈(matrix multiplication)  
- i번째 행벡터와 j번째 열벡터 사이의 내적을 성분으로 가지는 행렬을 계산한다  
-- **★ X의 열의 개수와 Y의 행의 개수가 같아야 함**  

![AI_class_01_01_13_07](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_07.png){: width="70%" height="70%"}{: .center}  

- numpy에서는 @연산 사용  

```python
X = np.array([[1,-2,3],
             [7,5,0],
             [-2,-1,2]])

Y = np.array([[0,1],
             [1,-1],
             [-2,1]])

X @ Y
```  

![AI_class_01_01_13_08](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_08.png){: width="50%" height="50%"}{: .center}  

>  
결과  
```
    array([[-8,  6],
        [ 5,  2],
        [-5,  1]])
```  

### 행렬의 내적  
- 넘파이의 np.inner은 i번째 행벡터와 j번째 행벡터 사이의 내적을 성분으로 가지는 행렬을 계산한다  
- 수학에서 말하는 내적과 다르므로 주의 (수학에서는 보통 ![AI_class_01_01_13_09](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_09.png){: .center}을 내적으로 계산함)  
-- **★ X의 행의 개수와 Y의 행의 개수가 같아야 함**  

![AI_class_01_01_13_10](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_10.png){: width="50%" height="50%"}{: .center}  

```python
X = np.array([[1,-2,3],
             [7,5,0],
             [-2,-1,2]])

Y = np.array([[0,1,-1],
             [1,-1,0]])

np.inner(X, Y)
```  

![AI_class_01_01_13_11](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_11.png){: width="50%" height="50%"}{: .center}  

>  
결과  
```
    array([[-5,  3],
        [ 5,  2],
        [-3, -1]])
```  

### 행렬 이해하기 2  
- 행렬은 벡터공간에서 사용되는 연산자(operator)로 이해한다  
- 행렬곱을 통해 벡터를 다른 차원의 공간으로 보낼 수 있다  
- 행렬곱을 통해 패턴을 추출할 수 있고 데이터를 압축할 수 있다  
-- 모든 선형변환(linear transform)은 행렬곱으로 계산할 수 있다  

![AI_class_01_01_13_12](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_12.png){: width="70%" height="70%"}{: .center}  

### 역행렬 이해하기  
- 역행렬(inverse matrix) : 어떤 행렬 A의 연산을 거꾸로 되돌리는 행렬  
- 표기 : ![AI_class_01_01_13_13](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_13.png){: .center}  
- 행과 열 숫자가 같고 행렬식(determinant)이 0이 아닌 경우에만 계산할 수 있다  
- 만일 역행렬을 계산할 수 없다면 유사역행렬(pseudo-inverse) 또는 무어-펜로즈(Moore-Penrose) 역행렬 ![AI_class_01_01_13_15](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_15.png){: .center}을 이용한다  

![AI_class_01_01_13_14](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_14.png){: width="70%" height="70%"}{: .center}  

- linalg.inv() 사용  

```python
X = np.array([[1,-2,3],
              [7,5,0],
              [-2,-1,2]])

np.linalg.inv(X)
```  
>  
결과  
```
    array([[ 0.21276596,  0.0212766 , -0.31914894],
        [-0.29787234,  0.17021277,  0.44680851],
        [ 0.06382979,  0.10638298,  0.40425532]])
```  

```python
X @ np.linalg.inv(X)
```  
>  
결과  
```
    array([[ 1.00000000e+00, -1.38777878e-17,  0.00000000e+00],
        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],
        [-2.77555756e-17,  0.00000000e+00,  1.00000000e+00]])
```  

![AI_class_01_01_13_16](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_16.png){: width="70%" height="70%"}{: .center}  

-- 행과 열의 개수가 달라서 역행렬을 계산할 수 없지만 pinv를 사용한다면 유사역행렬 가능  
- linalg.pinv() 사용  

```python
Y = np.array([[0,1],
             [1,-1],
             [-2,1]])

np.linalg.pinv(Y)
```  

>  
결과  
```
    array([[ 5.00000000e-01,  1.11022302e-16, -5.00000000e-01],
        [ 8.33333333e-01, -3.33333333e-01, -1.66666667e-01]])
```  

```python
np.linalg.pinv(Y) @ Y
```  

- **행이 열보다 많으면 유사역행렬은 원래 행렬보다 먼저 곱해야 항등행렬이 나온다**  

>  
결과  
```
    array([[ 1.00000000e+00, -2.22044605e-16],
        [ 1.11022302e-16,  1.00000000e+00]])
```  

## 응용 1 : 연립방정식 풀기  
- np.linalg.pinv를 이용하면 연립방정식의 해를 구할 수 있다  

![AI_class_01_01_13_17](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_17.png){: width="70%" height="70%"}{: .center}  

## 응용 2 : 선형회귀분석  
- np.linalg.pinv를 이용하면 데이터를 선형모델(linear model)로 해석하는 선형회귀식을 찾을 수 있다  

![AI_class_01_01_13_18](/images/2022-01-28-AI_class_01_01_13/AI_class_01_01_13_18.png){: width="70%" height="70%"}{: .center}  

- sklearn의 LinearRegression과 같은 결과를 가져올 수 있다  

```python
# Scikit Learn을 활용한 회귀분석
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X, y)
y_test = model.predict(x_test)

# Moore-Penrose 역행렬
X_ = np.array([np.append(x,[1]) for x in X]) # intercept 항 추가
beta = np.linalg.pinv(X_) @ y
y_test = np.append(x, [1]) @ beta
```  








임성빈 교수의 인공지능(AI) 강의를 들으며 정리하였습니다.  
또한 이곳저곳에서 구글링하며 공부하였습니다.  