---
layout: single
title:  "AI Class 01 01 22 PyTorch Basic Tensor Manipulation 1"
categories: python
tag: python
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
---

![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://{{ site.url | remove_first: 'https://' | remove_first: 'http://' }}{{ page.url }}&count_bg=%23FFCF00&title_bg=%230045FF&icon=macys.svg&icon_color=%23FAFF00&title=hits&edge_flat=false)


1차원 : Vector  
2차원 : Matrix  
3차원 : Tensor  

![AI_class_01_01_22_01](/images/2022-02-06-AI_class_01_01_22/AI_class_01_01_22_01.png){: width="50%" height="50%"}{: .center}  


### PyTorch Tensor Shape Convention  
- 2D Tensor (Typical Simple Setting)  

![AI_class_01_01_22_02](/images/2022-02-06-AI_class_01_01_22/AI_class_01_01_22_02.png){: width="50%" height="50%"}{: .center}  

- 3D Tensor (Typical Computer Vision)  

![AI_class_01_01_22_03](/images/2022-02-06-AI_class_01_01_22/AI_class_01_01_22_03.png){: width="50%" height="50%"}{: .center}  

- 3D Tensor (Typical Natural Language processing)  

![AI_class_01_01_22_04](/images/2022-02-06-AI_class_01_01_22/AI_class_01_01_22_04.png){: width="50%" height="50%"}{: .center}  

```python
# pip install torch
import numpy as np
import torch
```  

### Numpy  
#### 1D Array with Numpy  

```python
t = np.array([0.,1.,2.,3.,4.,5.,6.])
print(t)
print('Rank of t : ', t.ndim)
print('Shape of t : ', t.shape)
print('t[0] t[1] t[-1] = ', t[0], t[1], t[-1]) # Element
print('t[2:5] t[4:-1] = ', t[2:5], t[4:-1]) # Slicing
print('t[:2] t[3:] = ', t[:2], t[3:]) # Slicing
```  
>  
result  
```
    [0. 1. 2. 3. 4. 5. 6.]
    Rank of t :  1
    Shape of t :  (7,)
    t[0] t[1] t[-1] =  0.0 1.0 6.0
    t[2:5] t[4:-1] =  [2. 3. 4.] [4. 5.]
    t[:2] t[3:] =  [0. 1.] [3. 4. 5. 6.]
```  

#### 2D Array with Numpy  

```python
t = np.array([[1.,2.,3.], [4.,5.,6.], [7.,8.,9.], [10.,11.,12.]])
print(t)
print('Rank of t : ', t.ndim)
print('Shape of t : ', t.shape)
```  
>  
result  
```
    [[ 1.  2.  3.]
    [ 4.  5.  6.]
    [ 7.  8.  9.]
    [10. 11. 12.]]
    Rank of t :  2
    Shape of t :  (4, 3)
```  

### PyTorch Tensor  
#### 1D Array with PyTorch  

```python
t = torch.FloatTensor([0.,1.,2.,3.,4.,5.,6.])
print(t)
print(t.dim()) # rank
print(t.shape) # shape
print(t.size()) # shape
print(t[0], t[1], t[-1]) # Element
print(t[2:5], t[4:-1]) # Slicing
print(t[:2], t[3:]) # Slicing
```  
>  
result  
```
    tensor([0., 1., 2., 3., 4., 5., 6.])
    1
    torch.Size([7])
    torch.Size([7])
    tensor(0.) tensor(1.) tensor(6.)
    tensor([2., 3., 4.]) tensor([4., 5.])
    tensor([0., 1.]) tensor([3., 4., 5., 6.])
```  

#### 2D Array with PyTorch  

```python
t = torch.FloatTensor([[1.,2.,3.],
                      [4.,5.,6.],
                      [7.,8.,9.],
                      [10.,11.,12.]])
print(t)
print(t.dim()) # rank
print(t.size()) # shape
print(t[:, 1])
print(t[:, 1].size())
print(t[:, :-1])
```  
>  
result  
```
    tensor([[ 1.,  2.,  3.],
            [ 4.,  5.,  6.],
            [ 7.,  8.,  9.],
            [10., 11., 12.]])
    2
    torch.Size([4, 3])
    tensor([ 2.,  5.,  8., 11.])
    torch.Size([4])
    tensor([[ 1.,  2.],
            [ 4.,  5.],
            [ 7.,  8.],
            [10., 11.]])
```  

### Broadcasting  

```python
# Same shape
m1 = torch.FloatTensor([[3,3]])
m2 = torch.FloatTensor([[2,2]])
print(m1 + m2)
```  
>  
result  
```
    tensor([[5., 5.]])
```  

```python
# Vector + scalar
m1 = torch.FloatTensor([[1,2]])
print(m1.shape)
m2 = torch.FloatTensor([3]) # 3 -> [[3,3]]
print(m2.shape)
m3 = m1 + m2
print(m3.shape)
print(m3)
```  
>  
result  
```
    torch.Size([1, 2])
    torch.Size([1])
    torch.Size([1, 2])
    tensor([[4., 5.]])
```  

```python
# 2 x 1 Vector + 1 x 2 Vector
m1 = torch.FloatTensor([[1,2]])
print(m1.shape)
m2 = torch.FloatTensor([[3], [4]])
print(m2.shape)
m3 = m1 + m2
print(m3.shape)
print(m3)
```  
>  
result  
```
    torch.Size([1, 2])
    torch.Size([2, 1])
    torch.Size([2, 2])
    tensor([[4., 5.],
            [5., 6.]])
```  

### Multiplication vs Matrix Multiplication  

```python
print('-----------')
print('Mul vs Matmul')
print('-----------')
m1 = torch.FloatTensor([[1,2],[3,4]])
m2 = torch.FloatTensor([[1],[2]])
print('Shape of Matrix 1 : ', m1.shape) # 2 x 2
print('Shape of Matrix 2 : ', m2.shape) # 2 x 1
print(m1.matmul(m2)) # 2 x 1

m1 = torch.FloatTensor([[1,2],[3,4]])
m2 = torch.FloatTensor([[1],[2]])
print('Shape of Matrix 1 : ', m1.shape) # 2 x 2
print('Shape of Matrix 2 : ', m2.shape) # 2 x 1
print(m1 * m2) # 2 x 2
print(m1.mul(m2))
```  
>  
result  
```
-----------
Mul vs Matmul
-----------
Shape of Matrix 1 :  torch.Size([2, 2])
Shape of Matrix 2 :  torch.Size([2, 1])
tensor([[ 5.],
        [11.]])
Shape of Matrix 1 :  torch.Size([2, 2])
Shape of Matrix 2 :  torch.Size([2, 1])
tensor([[1., 2.],
        [6., 8.]])
tensor([[1., 2.],
        [6., 8.]])
```  

### Mean  

```python
t = torch.FloatTensor([1,2])
print(t.mean())
```  
>  
result  
```
    tensor(1.5000)
```  

```python
# Can't use mean() on integers
t = torch.LongTensor([1,2])
try:
    print(t.mean())
except Exception as exc:
    print(exc)
```  
>  
result  
```
    mean(): input dtype should be either floating point or complex dtypes. Got Long instead.
```  

```python
t = torch.FloatTensor([[1,2],[3,4]])
print(t)
```  
>  
result  
```
    tensor([[1., 2.],
            [3., 4.]])
```  
```python
print(t.mean())
print(t.mean(dim=0))
print(t.mean(dim=1))
print(t.mean(dim=-1))
```  
>  
result  
```
    tensor(2.5000)
    tensor([2., 3.])
    tensor([1.5000, 3.5000])
    tensor([1.5000, 3.5000])
```  

### Sum  

```python
t = torch.FloatTensor([[1,2],[3,4]])
print(t)
```  
>  
result  
```
    tensor([[1., 2.],
            [3., 4.]])
```  

```python
print(t.sum())
print(t.sum(dim=0))
print(t.sum(dim=1))
print(t.sum(dim=-1))
```  
>  
result  
```
    tensor(10.)
    tensor([4., 6.])
    tensor([3., 7.])
    tensor([3., 7.])
```  

### Max and Argmax  

```python
t = torch.FloatTensor([[1,2],[3,4]])
print(t)
```  
>  
result  
```
    tensor([[1., 2.],
            [3., 4.]])
```  

```python
print(t.max()) # Returns one value: max
```  
>  
result  
```
    tensor(4.)
```  

```python
print(t.max(dim=0)) # Return two values: max and argmax
print('Max : ', t.max(dim=0)[0])
print('Argmax : ', t.max(dim=0)[1])
```  
>  
result  
```
    torch.return_types.max(
    values=tensor([3., 4.]),
    indices=tensor([1, 1]))
    Max :  tensor([3., 4.])
    Argmax :  tensor([1, 1])
```  

```python
print(t.max(dim=1))
print(t.max(dim=-1))
```  
>  
result  
```
    torch.return_types.max(
    values=tensor([2., 4.]),
    indices=tensor([1, 1]))
    torch.return_types.max(
    values=tensor([2., 4.]),
    indices=tensor([1, 1]))
```  


김기현 교수의 인공지능(AI) 강의를 들으며 정리하였습니다.  
또한 이곳저곳에서 구글링하며 공부하였습니다.  